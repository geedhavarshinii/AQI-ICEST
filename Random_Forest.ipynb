{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKzyL7NGkMxD"
      },
      "source": [
        "# Import necessary modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f8AJ8yHyfWLQ"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7uV1YzsJkTP2"
      },
      "source": [
        "# Load the dataset and split the dataset to test and train variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVoEbRT1gKMl",
        "outputId": "8560e6fa-639b-4dd8-c607-3b9787a6ffb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "X_train shape: (2517657, 17)\n",
            "X_test shape: (1078996, 17)\n",
            "y_train shape: (2517657,)\n",
            "y_test shape: (1078996,)\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/processed_data1.csv\")\n",
        "\n",
        "# Encode categorical columns\n",
        "label_encoder = LabelEncoder()\n",
        "df['Region'] = label_encoder.fit_transform(df['Region'])\n",
        "df['Day_period'] = label_encoder.fit_transform(df['Day_period'])\n",
        "df['Season'] = label_encoder.fit_transform(df['Season'])\n",
        "df['Weekday_or_weekend'] = label_encoder.fit_transform(df['Weekday_or_weekend'])\n",
        "df['Regular_day_or_holiday'] = label_encoder.fit_transform(df['Regular_day_or_holiday'])\n",
        "\n",
        "# Define features and target including encoded columns\n",
        "features = df[['PM2.5', 'PM10', 'NO', 'NO2', 'NOx', 'NH3', 'CO', 'SO2', 'O3', 'Benzene', 'Toluene',\n",
        "               'Region', 'Day_period', 'Month_encoded', 'Season', 'Weekday_or_weekend', 'Regular_day_or_holiday']]\n",
        "target = df['AQI']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3, random_state=42)\n",
        "\n",
        "# Print the shapes of the splits to ensure consistency\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3o60CJFkYya"
      },
      "source": [
        "# Initialize the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4d7wBxV-kbfz"
      },
      "outputs": [],
      "source": [
        "# Initialize the model\n",
        "rf_model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "rf_model.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FO26mjPnYp9"
      },
      "source": [
        "# Predict using various metrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l7v4Wx2E63YK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Calculate R² (Coefficient of Determination)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "# Recall (Sensitivity) - Not applicable for regression models\n",
        "recall = None\n",
        "\n",
        "# Accuracy - Not applicable for regression models\n",
        "accuracy = None\n",
        "\n",
        "# Calculate MAPE (Mean Absolute Percentage Error)\n",
        "mape = mean_absolute_percentage_error(y_test, y_pred)\n",
        "\n",
        "# Calculate MAE (Mean Absolute Error)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "\n",
        "# Calculate RMSE (Root Mean Square Error)\n",
        "rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Print the calculated metrics\n",
        "print(\"R² (Coefficient of Determination):\", r2)\n",
        "print(\"Recall (Sensitivity):\", recall)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"MAPE (Mean Absolute Percentage Error):\", mape)\n",
        "print(\"MAE (Mean Absolute Error):\", mae)\n",
        "print(\"RMSE (Root Mean Square Error):\", rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yq94k1dEnc_A"
      },
      "source": [
        "# Plot graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6kd48eZUrHN"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a dictionary with the metrics\n",
        "metrics = {\n",
        "    'R²': r2,\n",
        "    'MAPE': mape,\n",
        "    'MAE': mae,\n",
        "    'RMSE': rmse\n",
        "}\n",
        "\n",
        "# Plot performance metrics\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.barh(list(metrics.keys()), list(metrics.values()), color='skyblue')\n",
        "plt.xlabel('Metric Value')\n",
        "plt.title('Model Performance Metrics')\n",
        "plt.gca().invert_yaxis()  # Invert y-axis to display metrics from top to bottom\n",
        "plt.show()\n",
        "\n",
        "# Analyze the metrics\n",
        "for metric, value in metrics.items():\n",
        "    print(f\"The model's {metric} is {value}.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnZtpVToWS2_"
      },
      "source": [
        "# Model Improvement: Hyperparameter Tuning using Grid Search\n",
        "grid search cv is used to find better predictions. A random forest has fixed param grid and in this hyper tuning, we give multiple values for each parameter and we test the model on those combinations. 3* 4* 3* 3 so 108 random forests will be generated with 3 different values for 4 param grid. by this, we can use the best param grid and hence better prediction.\n",
        "\n",
        "Calling the gridsearchcv function, we pass parameters, cv is cross validation meaning how many times we train the model with the param grid. The value is 5 so train 108 random forests 5 times. n_jobs =-1 is to make model work faster.\n",
        "\n",
        "Randomsearchcv is faster and it chooses random 10/20/30 random forests from the 108 random forests. But best results are not guaranteed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rUtSBUFtWUX7"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "param_dist = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'min_samples_split': randint(2, 11),  # Using randint for random integer sampling\n",
        "    'min_samples_leaf': randint(1, 5)    # Using randint for random integer sampling\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist, n_iter=100,\n",
        "                                   cv=5, scoring='neg_mean_squared_error', n_jobs=-1, random_state=42)\n",
        "\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = random_search.best_params_\n",
        "best_rf_model = random_search.best_estimator_\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}